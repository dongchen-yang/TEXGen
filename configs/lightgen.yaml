name: lightgen
tag: "v1"
exp_root_dir: "outputs"
seed: 42

# Data configuration
data_cls: spuv.data.lightgen_uv.LightGenDataModule
data:
  data_root: "../data/baked_uv_local"
  parquet_file: "../data/baked_uv_local/df_SomgProc_filtered.parquet"
  scene_list: ""
  eval_scene_list: ""
  repeat: 1
  vertex_transformation: false
  cond_views: 1
  sup_views: 4
  camera_strategy: "strategy_1"
  eval_cond_views: 1
  eval_sup_views: 4
  eval_camera_strategy: "strategy_test_1_to_4_90deg"

  # Using specific sample 416f4870df6449dfaf9533be8aa18701 for overfitting test
  # Index 761778 in success-filtered dataframe (not 787608!)
  train_indices: [761778, 761779]     # 1 sample for training
  val_indices: [761778, 761779]       # Same 1 sample for validation
  test_indices: [761778, 761779]      # Same 1 sample for testing

  height: 512
  width: 512
  uv_height: 512
  uv_width: 512
  batch_size: 1
  num_workers: 0  # No workers needed for 1 sample

# System configuration
system_cls: spuv.systems.lightgen_system.LightGenSystem
system:
  condition_drop_rate: 0.0  # Disable dropout for overfitting test
  rescale_betas_zero_snr: true
  use_ema: false  # Disable EMA for faster overfitting
  ema_decay: 0.9999
  render_background_color: [0.0, 0.0, 0.0]
  train_regression: false
  recon_warm_up_steps: 0
  prediction_type: "v_prediction"  # or "epsilon" or "sample"
  check_train_every_n_steps: 10  # Check more frequently
  test_save_json: false

  test_cfg_scale: 2.0  # Classifier-free guidance scale
  test_num_steps: 50   # Number of denoising steps
  guidance_rescale: 0.0
  guidance_interval: [0.0, 1.0]

  # Data augmentation (disabled for UV space)
  cond_rgb_perturb: false

  # Image tokenizer (for conditioning on material/albedo)
  image_tokenizer_cls: spuv.models.tokenizers.clip.ClipTokenizer
  image_tokenizer:
    pretrained_model_name_or_path: "lambdalabs/sd-image-variations-diffusers"

  # Backbone network - Simple U-Net for UV space (no 3D baking needed!)
  backbone_cls: spuv.models.simple_uv_unet.SimpleUVUNet
  backbone:
    in_channels: 11  # position(3) + normal(3) + albedo(3) + metal(1) + rough(1)
    out_channels: 3  # emission RGB
    base_channels: 64  # Base number of channels (increase for more capacity)
    time_emb_dim: 256  # Time embedding dimension

  # Loss configuration
  loss:
    diffusion_loss_dict:
      lambda_mse: 1.0
      lambda_l1: 0.5
    render_loss_dict:
      lambda_render_lpips: 0.0
      lambda_render_mse: 0.0
      lambda_render_l1: 0.0
    use_min_snr_weight: false
    use_vgg: false

  # Optimizer
  optimizer:
    name: AdamW
    args:
      lr: 5e-4  # Higher LR for faster overfitting
      betas: [0.9, 0.999]
      weight_decay: 0.0  # No weight decay for overfitting

  # Learning rate scheduler
  scheduler:
    name: CosineAnnealingLR
    interval: step
    args:
      T_max: 100000
      eta_min: 1e-6

# Trainer configuration
trainer:
  max_epochs: 1000  # 1000 epochs for thorough overfitting test
  check_val_every_n_epoch: 10000  # Disable validation (set very high)
  num_sanity_val_steps: 0  # Skip sanity checks
  precision: bf16-mixed
  strategy: auto  # Simpler strategy for single sample
  gradient_clip_val: 1.0
  num_nodes: 1
  limit_val_batches: 0  # Disable validation completely

# Checkpoint configuration
checkpoint:
  save_last: true
  save_top_k: 1
  every_n_epochs: 20
  monitor: "val/psnr"
  mode: "max"
  save_on_train_epoch_end: false  # Wait for validation before saving

